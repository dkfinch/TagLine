# Configuration file for TagLine when using TagLineApp class

# Task to be performed.
# Valid options:
#  t - train a classifier
#  s - score non-labeled lines
#  i - identify structures
#  e - evaluate performance using cross-validation
#  c - create a synthetic dataset
task.type 						= i

# Log file (leave blank for none)
file.output.log					= c:/data/log.txt

# =============================================================
# Task Type t - train a classifier
# =============================================================

# Tab-delimited file with doc_id, line_num, class, and text
train.file.input.dataset		= c:/data/ALLSHE.txt

# Outputs model needed for scoring
train.file.output.model			= c:/data/ALLSHE.tlmod

# Outputs data with all features [tab-delimited] (leave blank for none)
train.file.output.dataset		= c:/data/ALLSHEfeats.txt

# Which classifier type to build a classification model
# Valid options:
#  J48 - C4.5 decision tree
#  LMT - Logistic model tree
#  RandomForest - Forest of random trees
#  SVM - Support vector machine (LibSVM)
train.classifier.type			= J48

# Options/parameters for selected classifier type. Leave blank for default options.
# See Weka documentation for options/parameters and format.  
# Each separate option must be on a new line. Options with have both a label
# and a value must be on two separate lines (e.g., -M 10 should be -M on one 
# line and 10 on another line). Example shown below.
# train.classifier.options		= -R
# train.classifier.options		= -M
# train.classifier.options		= 5
# train.classifier.options		= -Q 
# train.classifier.options		= 1111
train.classifier.options		= 


# =============================================================
# Task Type s - score non-labeled lines
# =============================================================

# Either a directory with each document as a separate file
# or a tab-delimited file with doc_id, line_num, and text
score.file.input.dataset		= C:/data/TestNotes
#score.file.input.dataset		= C:/data/AllTest2.txt
#c:/data/syndata_scoring.txt

# Classification model  (obtained from task.type = t)
score.file.input.model			= c:/data/ALLSHE.tlmod

# Outputs tab-delimited file with doc_id, line_num, text, and predicted label
score.file.output.dataset.scored	= c:/data/ALLSHEscored.txt

# Outputs tab-delimited file with all features and predicted label (leave blank for none)
score.file.output.dataset.features	= c:/data/ALLSHEscoring_feats.txt


# =============================================================
# Task Type i - identify structures
# =============================================================

# Tab-delimited file with doc_id, line_num, text, and label
identify.file.input.dataset			= c:/data/ALLSHEscored.txt

# Whether to identify check boxes (true = yes | false = no)
identify.struc.checkboxes			= true

# Whether to identify free text (true = yes | false = no)
identify.struc.freetext				= true

# Whether to identify lists (true = yes | false = no)
identify.struc.lists				= true

# Whether to identify medications (true = yes | false = no)
identify.struc.medications			= true

# Whether to identify questions (true = yes | false = no)
identify.struc.questions			= true

# Whether to identify slot-fillers (true = yes | false = no)
identify.struc.slotfillers			= true

# Whether to identify tables (true = yes | false = no)
identify.struc.tables				= true

# Whether to identify vitals (true = yes | false = no)
identify.struc.vitals				= true

# Comma separated list of user-defined structures to identify
#identify.struc.userdefined			= class2, class4, she

# Outputs tab-delimited file with doc_id, annotation_start, annotation_end, annotation_type
identify.file.output.annotations	= c:/data/ALLSHEannotated.txt

# =============================================================
# Task Type e - perform evaluation using cross-validation
# =============================================================

# Tab-delimited file with doc_id, line_num, class, and text
eval.file.input.dataset			= c:/data/syndata.txt

# Outputs performance measures
eval.file.output.performance	= c:/data/synperf.txt

# Which classifier type to build a classification model
# Valid options:
#  J48 - C4.5 decision tree
#  LMT - Logistic model tree
#  RandomForest - Forest of random trees
#  SVM - Support vector machine (LibSVM)
eval.classifier.type			= J48

# Options/parameters for selected classifier type. Leave blank for default options.
# See Weka documentation for options/parameters and format.  
# Each separate option must be on a new line. Options with have both a label
# and a value must be on two separate lines (e.g., -M 10 should be -M on one 
# line and 10 on another line). Example shown below.
# eval.classifier.options		= -R
# eval.classifier.options		= -M
# eval.classifier.options		= 5
# eval.classifier.options		= -Q 
# eval.classifier.options		= 1111
eval.classifier.options			= 


# =============================================================
# Task Type c - create a synthetic dataset
# =============================================================

# Outputs a tab-delimited file with doc_id, line_num, class (possibly), and text
create.file.output.dataset		= C:/data/syndata.txt

# How many line classes to create
# Set to 0 if class information should not be included
create.classes					= 25

# How many documents to create
create.docs						= 10

# Maximum number of lines per document to create (randomly determined)
create.maxlinesperdoc			= 50

# Maximum line length in characters (randomly determined)
create.maxlinelength			= 80

# Random seed used in randomization
create.randomseed				= 1111
